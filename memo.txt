
【音声教材デジタル化】
＜作成予定機能＞

・画像の前処理
　└ 設問ごとに画像を切り出す。その手法は下記検討中。
　　－白いページで分離（その他の背景は自動削除）（グレースケールより、RGB値の差分が大きいか、にする？白い画像以外は削除するため。自分で実装 or pythonでライブラリ探す）
　　－罫線や余白で分離
　　－設問Noの位置で分離

・文字起こし
　└ 改行が入っている文章を一文にまとめる（ピリオドで区切る？）  
　└ sentenceにlanguageデータを追加（wordのlanguageをappendする。重複無しのappendするには、if文使うしかなさげ） 
　└ [Done]文字(単語)の識字精度が一定未満(70％～80％？→ 70%でよさそう)なら、下記二つを実施して手動補正を促す。
　　－出力するテキストファイルの対象文字を""でくくる or 別の文字で置換？（前者の方が候補提示になるので、前者）
　　　→ 0～50%：エラー、51%～80%: warning, 81%～100%: Successにする？ ERROR_BORDER = 0.5, WARNING_BORDER = 0.8のように
　　－文字起こしした画像の対象位置を赤枠で囲う（囲うときは座標を±5くらいするとよさげ）。
　└ [Done]関係ない文字（画像内の写真や無関係なオブジェクト）をフィルターアウトするために、識字率が一定以下は削除が良さそう。
　　ただし、削除した旨と削除した箇所は元画像に図示する（枠の色は上記とは変える）

・音声作成
　└ 対話形式に対応（音声を関数の引数に）
　└ [Done]音声のスピードを関数の引数に
　└ 文と文の間にpauseを入れる（ssmlで実装）
★└ 異なる音声を一つのファイルに（googleより、ffmpegで実装になりそう）



＜パターン＞
・OCRのみ
　└ テキスト保存
・OCR＋Speech化（話者1人）
　└ テキストString返す＋テキストinputで音声返す
・OCR＋Speech化（話者2人）
　└ テキストString返す（話者で分解）＋一つの音声データ


Part1: 話者一人
Part2: 話者一人
Part3: 話者二人
Part4: 話者2～3人

＜方針＞
・パターンの一つ目は無視
・パターンの二つ目か三つ目のみ対応させることにする。
・パターンの三つ目は時間あれば。まずは二つ目のみ。
